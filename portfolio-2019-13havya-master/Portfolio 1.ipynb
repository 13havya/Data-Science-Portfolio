{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import sklearn.metrics\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Cycling Data\n",
    "\n",
    "## Loading Data\n",
    "\n",
    "The first dataset is an export of my ride data from [Strava](https://strava.com/), an online social \n",
    "network site for cycling and other sports.  This data is a log of every ride since the start of 2018\n",
    "and contains summary data like the distance and average speed.  It was exported using \n",
    "the script `stravaget.py` which uses the stravalib module to read data. Some details of\n",
    "the fields exported by that script can be seen in [the documentation for stravalib](https://pythonhosted.org/stravalib/api.html#stravalib.model.Activity). \n",
    "\n",
    "The exported data is a CSV file so that's easy to read, however the date information in the file is \n",
    "recorded in a different timezone (UTC) so we need to do a bit of conversion.  In reading the data I'm\n",
    "setting the index of the data frame to be the datetime of the ride. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strava = pd.read_csv('data/strava_export.csv', index_col='date', parse_dates=True)\n",
    "strava.index = strava.index.tz_convert('Australia/Sydney')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dataset comes from an application called [GoldenCheetah](https://www.goldencheetah.org/) which provides\n",
    "some analytics services over ride data.  This has some of the same fields but adds a lot of analysis of the \n",
    "power, speed and heart rate data in each ride.  This data overlaps with the Strava data but doesn't include all \n",
    "of the same rides. \n",
    "\n",
    "Again we create an index using the datetime for each ride, this time combining two columns in the data (date and time) \n",
    "and localising to Sydney so that the times match those for the Strava data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cheetah = pd.read_csv('data/cheetah.csv', skipinitialspace=True)\n",
    "cheetah.index = pd.to_datetime(cheetah['date'] + ' ' + cheetah['time'])\n",
    "cheetah.index = cheetah.index.tz_localize('Australia/Sydney')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GoldenCheetah data contains many many variables (columns) and I won't go into all of them here. Some\n",
    "that are of particular interest for the analysis below are:\n",
    "\n",
    "Here are definitions of some of the more important fields in the data. Capitalised fields come from the GoldenCheetah data\n",
    "while lowercase_fields come from Strava. There are many cases where fields are duplicated and in this case the values\n",
    "should be the same, although there is room for variation as the algorithm used to calculate them could be different\n",
    "in each case. \n",
    "\n",
    "  * Duration - overall duration of the ride, should be same as elapsed_time\n",
    "  * Time Moving - time spent moving (not resting or waiting at lights), should be the same as moving_time\n",
    "  * Elevation Gain - metres climbed over the ride\n",
    "  * Average Speed - over the ride\n",
    "  * Average Power - average power in watts as measured by a power meter, relates to how much effort is being put in to the ride, should be the same as  * average_watts' from Strava\n",
    "  * Nonzero Average Power - same as Average Power but excludes times when power is zero from the average\n",
    "  * Average Heart Rate - should be the same as average_heartrate\n",
    "  * Average Cadence - cadence is the rotations per minute of the pedals\n",
    "  * Average Temp - temperature in the environment as measured by the bike computer (should be same as average_temp)\n",
    "  * VAM - average ascent speed - speed up hills\n",
    "  * Calories (HR) - Calorie expendature as estimated from heart rate data\n",
    "  * 1 sec Peak Power - this and other  'Peak Power' measures give the maximum power output in the ride over this time period.  Will be higher for shorter periods. High values in short periods would come from a very 'punchy' ride with sprints for example.\n",
    "  * 1 min Peak Hr - a similar measure relating to Heart Rate\n",
    "  * NP - Normalised Power, a smoothed average power measurement, generally higher than Average Power \n",
    "  * TSS - Training Stress Score, a measure of how hard a ride this was\n",
    "  * device_watts - True if the power (watts) measures were from a power meter, False if they were estimated\n",
    "  * distance - distance travelled in Km\n",
    "  * kudos - likes from other Strava users (social network)\n",
    "  * workout_type - one of  'Race',  'Workout' or  'Ride'\n",
    "  \n",
    "  \n",
    "Some of the GoldenCheetah parameters are defined [in thier documentation](https://github.com/GoldenCheetah/GoldenCheetah/wiki/UG_Glossary).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Tasks\n",
    "\n",
    "Your first task is to combine these two data frames using the [`join` method of Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#joining-on-index).   The goal is to keep only those rows of data \n",
    "that appear in __both__ data frames so that we have complete data for every row.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_data = strava.join(cheetah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwork = ride_data[ride_data.workout_type == 'Workout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_data.dropna(subset = [\"device_watts\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = ride_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = rd[rd.device_watts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.drop(['filename', 'date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z=rd[['Distance', 'Time Moving' , 'Average Speed', 'Average Heart Rate', 'average_watts','NP', 'TSS', 'Elevation Gain' ]]\n",
    "##scattermat = pd.plotting.scatter_matrix(z, marker = \".\", diagonal='kde', figsize=(15,15), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.drop(['elapsed_time', 'moving_time'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = rd.Duration/60\n",
    "rd['Duration_minutes'] = mins\n",
    "rd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale = 1.5)\n",
    "seapair = sns.pairplot(z, diag_kind='kde', palette= 'bright', height= 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Analysis\n",
    "\n",
    "1. Remove rides with no measured power (where device_watts is False) - these are commutes or MTB rides\n",
    "* Look at the distributions of some key variables: time, distance, average speed, average power, TSS. Are they normally distributed? Skewed? \n",
    "* Explore the relationships between the following variables. Are any of them corrolated with each other (do they vary together in a predictable way)? Can you explain any relationships you observe?  \n",
    "    * Distance\n",
    "    * Moving Time\n",
    "    * Average Speed\n",
    "    * Heart Rate\n",
    "    * Power (watts)\n",
    "    * Normalised power (NP)\n",
    "    * Training Stress Score\n",
    "    * Elevation Gain\n",
    "* We want to explore the differences between the three categories: `Race`, `Workout` and `Ride`.\n",
    "    * Use scatter plots with different colours for each category to explore how these categories differ.  \n",
    "    * Use histograms or box plots to visualise the different distributions of a variable for the three categories.\n",
    "    * In both cases, experiment with different variables but only include those that are interesting in your final notebook (if none are interesting, show us a representative example).\n",
    "\n",
    "\n",
    "## Challenge\n",
    "\n",
    "* What leads to more `kudos`? Is there anything to indicate which rides are more popular? Explore the relationship between the main variables and kudos. Show a plot and comment on any relationship you observe. \n",
    "\n",
    "* Generate a plot that summarises the number of km ridden each month over the period of the data. Overlay this with the _sum_ of the Training Stress Score and the _average_ of the Average Speed to generate an overall summary of activity.\n",
    "\n",
    "* Generate a similar graph but one that shows the activity over a given month, with the sum of the values for each day of the month shown.  So, if there are two rides on a given day, the graph should show the sum of the distances etc for these rides.\n",
    "\n",
    "Hint: to generate these summary plots you need to use the [timeseries/date functionality](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html) in Pandas to generate a new data frame containing the required data.  \n",
    "\n",
    "__Note:__ once you have completed these steps you can remove this cell.  Use the text as a starting point for the documentation of your workflow and discussion of results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = rd[rd.workout_type == \"Race\"]\n",
    "ride = rd[rd.workout_type == \"Ride\"]\n",
    "work= rd[rd.workout_type == \"Workout\"]\n",
    "x = ['Distance', 'kudos', 'Time Moving', 'Average Heart Rate', 'Duration_minutes', 'Average Power', 'Work', 'Average Speed', 'Calories (HR)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = race[x]\n",
    "ride = ride[x]\n",
    "work = work[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Data #\n",
    "\n",
    "## Scatterplots for Comparison of variables in Race, Ride and Workout ##\n",
    "\n",
    "* ### Race ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,10))\n",
    "sns.set_style('darkgrid')\n",
    "with sns.xkcd_palette(['green', 'purple', 'red']) :\n",
    "    sns.lmplot(x = 'Distance', y = 'Duration_minutes', data = rd, fit_reg= False,\n",
    "           hue = 'workout_type', legend_out= True, scatter_kws= {\"s\" : 20}, height = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is evidence of a **linear** relationship between the variables Distance and Duration for the category Race and Ride, however, we do not have enough data for Workouts to hypothesize a relationship between Duration and Distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,10))\n",
    "sns.set_style('darkgrid')\n",
    "with sns.xkcd_palette(['green', 'purple', 'red']) :\n",
    "    sns.lmplot(x = 'Distance', y = 'Duration_minutes', data = rd, fit_reg= True,\n",
    "           hue = 'workout_type', legend_out= True, scatter_kws= {\"s\" : 20}, height = 7)\n",
    "    plt.ylabel('Duration (in minutes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is to be noted that the variable **x** is **Distance**, while variable **y** is **Duration**. It can be explained by the regression lines that as distance increases, so does duration. It is to be noted that the slope is highest for the category *Ride*, meaning that, the average speed during a Ride should be less compared to the other two variables. It can be assumed from the regression line that the average speed in a Race is higher than a Ride. It is also seen that Workout has the least slope, meaning, in theory it should have the highest average speed. But one should keep in mind that the Workout category only has 5 observations, and the distance and duration is much lesser than the other two categories, which is a contributing factor in a result that may be skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxdist = rd.boxplot(by = 'workout_type', column = ['distance'], figsize = (7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category **ride** has the highest median distance covered per ride. It also has the highest range, meaning that it had a significant number of short and long distance rides. The median distace for **races** and **workouts** are almost the same, however, the spread for **races** is larger. They also have some outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpowerbox = rd.boxplot(by = 'workout_type', column = ['Average Power'], figsize = (7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median power is the highest for **races**. The median for **workouts** is quite close to the maximum value, indicating that the power output was mostly high. However, it can be traced to the fact that the number of observations is quite low. **Rides** have the highest spread of power output, but have the lowest median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgspeedbox = rd.boxplot(by = 'workout_type', column = ['Average Speed'], figsize = (7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of speed is compact for all three categories. **Workouts** have the lowest spread, but have an outlier that is significantly less than its lower quartile. **Races** have the highest median value, whereas **rides** have the lowest median and highest spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_hist = plt.hist(rd['Duration'], bins = 20)\n",
    "z = plt.title(\"Distribution of Duration as a Histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_hist = plt.hist(rd['Distance'], bins = 20)\n",
    "z = plt.title(\"Distance distribution as a histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of distance seems to be **bimodal**, however, the second mode is much more distinct compared to the first mode. The observations towards the right end of the histogram are very small, meaning that high distance rides were less frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_speed_hist = plt.hist(rd['Average Speed'], bins = 20)\n",
    "z = plt.title(\"Distribution of Average Speed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of average speed is **skewed to the right**. This means that the **mean is higher than the median** of the data. The number of high average speed rides were significantly less, which resulted in a high mean, but did not affect the median value much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_power_hist = plt.hist(rd['Average Power'], bins = 20)\n",
    "z = plt.title(\"Distribution of Average Power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution for average power is **normally distributed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_hist = plt.hist(rd['TSS'], bins = 20)\n",
    "z = plt.title(\"Distribution of TSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution for training stress score is **bimodal**. There are some high scored observations, but their frequency is quite low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd['Month'] = rd.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {1:'January', 2 : 'February', 3 : 'March', 4: 'April', 5:'May', 6: 'June', 7: 'July', 8 : 'August', 9 : 'September', 10 : 'October', 11: 'November', 12: 'December'}\n",
    "rd['Month'] = rd['Month'].map(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,12))\n",
    "sns.barplot(y = 'Distance', x = 'Month', data = rd, ci = None, orient='v', palette= 'gist_heat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the total distance ridden during each month. It can be noted that in **October**, over 60km was covered in bike rides. **June** and **August** had the least distance covered, with both measuring a little over 30km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kudos = rd['kudos']\n",
    "feature_cols = np.array(['Distance', 'Time Moving', 'Average Heart Rate', 'Duration_minutes', 'Average Power', 'Work', 'Average Speed', 'Calories (HR)', 'Elevation Gain'])\n",
    "X = rd[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LinearRegression()\n",
    "selector  = RFE(estimator, 9)\n",
    "selector = selector.fit(X, kudos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = selector.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(pred, kudos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(kudos, hist = False, kde_kws={'color' : 'r'})\n",
    "sns.distplot(pred, hist = False, kde_kws = {'color' : 'k'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An $ R^2 $ score of $ 0.6 $ or $ 60 \\%\\ $ indicates that the predictor model is a decent fit of our actual model, although it does deviate from it at certain instances.\n",
    "\n",
    "The **red** graph depicts the distribution of kudos from the actual data. The **black** graph depicts the prediction of kudos with the algorithm. It can be seen that the predictor follows the data closely upto most extent, except for a spike around **20** units, where our predictor's estimates are significantly higher than the actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols[supp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression Coefficients \\n\")\n",
    "for i in range(len(feature_cols[supp])):\n",
    "    print(feature_cols[supp][i] , \":\", round(selector.estimator_.coef_[i], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance** has a regression coefficient of 0.22, which implies that the change in value of distance has the most impact (out of these given variables), on the value of kudos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = []\n",
    "for i in rd.index:\n",
    "    months.append(str(i.month) + \"/\" + str(i.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.array(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = rd[['TSS', 'Average Speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['months'] = months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop('date', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_sum = dict()\n",
    "for x in range(len(dat.months)):\n",
    "    if (dat.months[x]) in tss_sum:\n",
    "        tss_sum[dat.months[x]] += dat.TSS[x]\n",
    "    else:\n",
    "        tss_sum[dat.months[x]] = dat.TSS[x]s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "for i in tss_sum:\n",
    "    for j in dat.months:\n",
    "        if (i == j):\n",
    "            l1.append(tss_sum[j])\n",
    "list1 = []\n",
    "for j in l1:\n",
    "    x = j/100\n",
    "    list1.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_spd = dict()\n",
    "for x in range(len(dat.months)):\n",
    "    if (dat.months[x]) in avg_spd:\n",
    "        avg_spd[dat.months[x]] += dat['Average Speed'][x]\n",
    "    else:\n",
    "        avg_spd[dat.months[x]] = dat['Average Speed'][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = dict()\n",
    "for i in dat.months:\n",
    "    if i in counter:\n",
    "        counter[i] += 1\n",
    "    else:\n",
    "        counter[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_avg_speed = []\n",
    "for i in avg_spd:\n",
    "    avg_avg_speed.append(avg_spd[i]/counter[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "for i in avg_spd:\n",
    "    for j in dat.months:\n",
    "        if (i == j):\n",
    "            l2.append(avg_spd[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for i in l2:\n",
    "    j = i/100\n",
    "    list2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['Monthly TSS Sum (in 100\\'s)'] = list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['Monthly Average Avg Speed (in 100 km/h)'] = list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(rd.Distance)\n",
    "dat['Distance'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,7))\n",
    "plt.plot(dat.index,dat['Distance'], c = 'r')\n",
    "plt.plot(dat.index, dat['Monthly TSS Sum (in 100\\'s)'], c = 'g')\n",
    "plt.plot(dat.index, dat['Monthly Average Avg Speed (in 100 km/h)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kudos = pd.DataFrame(kudos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday = kudos.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekstatus = []\n",
    "for i in weekday:\n",
    "    if (i > 5):\n",
    "        weekstatus.append(0)\n",
    "    else:\n",
    "        weekstatus.append(1)\n",
    "kudos['isWeekend'] = weekstatus\n",
    "kudos['isWeekend'] = kudos['isWeekend'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "feature_col = ['kudos']\n",
    "X = kudos[feature_col]\n",
    "y = kudos['isWeekend']\n",
    "logreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logreg.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = np.append(feature_cols,'kudos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_graph = rd[feat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_graph = feat_graph.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.style.use('default')\n",
    "heatmap = sns.heatmap(feat_graph, square = True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap shows correlation of some of the key variables in the dataset. The darker shades imply a higher correlation value, as compared to lighter shades. Here, we are not concerned with the diagonal running from the top-left to the bottom right, as it just shows the correlation of each variable with itself (which is always 1). \n",
    "\n",
    "It is important to note that correlation does not imply causation. If two variables are correlated, it does not mean that one causes the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
